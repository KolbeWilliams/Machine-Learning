{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyDYlw1k8nmm",
        "outputId": "9fbcadd8-bf27-46db-9a9e-90e20edd6512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 13783.41794720\n",
            "Iteration 2, loss = 5143.58632298\n",
            "Iteration 3, loss = 2656.49312984\n",
            "Iteration 4, loss = 1970.83790419\n",
            "Iteration 5, loss = 1849.01221692\n",
            "Iteration 6, loss = 1692.41892457\n",
            "Iteration 7, loss = 1614.73698556\n",
            "Iteration 8, loss = 1579.30944173\n",
            "Iteration 9, loss = 1536.27820279\n",
            "Iteration 10, loss = 1694.91173752\n",
            "Iteration 11, loss = 1526.74184262\n",
            "Iteration 12, loss = 1490.43789817\n",
            "Iteration 13, loss = 1501.71663923\n",
            "Iteration 14, loss = 1462.00187776\n",
            "Iteration 15, loss = 1469.17253691\n",
            "Iteration 16, loss = 1506.65427341\n",
            "Iteration 17, loss = 1484.33484426\n",
            "Iteration 18, loss = 1462.85881891\n",
            "Iteration 19, loss = 1486.41003650\n",
            "Iteration 20, loss = 1457.89571500\n",
            "MSE for model 1: 2881.031579051531\n",
            "R2 score for model 1: 0.4562195052532849\n",
            "\n",
            "Iteration 1, loss = 14658.55646548\n",
            "Iteration 2, loss = 13374.61810204\n",
            "Iteration 3, loss = 7447.55243600\n",
            "Iteration 4, loss = 2903.58803549\n",
            "Iteration 5, loss = 2757.64546830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 6, loss = 2641.12238418\n",
            "Iteration 7, loss = 2549.44704675\n",
            "Iteration 8, loss = 2457.06401555\n",
            "Iteration 9, loss = 2376.00723127\n",
            "Iteration 10, loss = 2325.82151369\n",
            "Iteration 11, loss = 2238.72030397\n",
            "Iteration 12, loss = 2187.28355810\n",
            "Iteration 13, loss = 2096.73327298\n",
            "Iteration 14, loss = 2066.25041734\n",
            "Iteration 15, loss = 1983.48808276\n",
            "Iteration 16, loss = 1940.99957382\n",
            "Iteration 17, loss = 1881.18453674\n",
            "Iteration 18, loss = 1855.33609096\n",
            "Iteration 19, loss = 1803.61180587\n",
            "Iteration 20, loss = 1792.20338951\n",
            "MSE for model 2: 3146.063760955376\n",
            "R2 score for model 2: 0.4061959886603429\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 14783.88763429\n",
            "Iteration 2, loss = 14488.48354658\n",
            "Iteration 3, loss = 13448.51854226\n",
            "Iteration 4, loss = 10313.88656793\n",
            "Iteration 5, loss = 4517.35259297\n",
            "Iteration 6, loss = 3182.46594362\n",
            "Iteration 7, loss = 2472.41381381\n",
            "Iteration 8, loss = 2279.96163651\n",
            "Iteration 9, loss = 2077.49448694\n",
            "Iteration 10, loss = 1992.58616985\n",
            "Iteration 11, loss = 1968.47827932\n",
            "Iteration 12, loss = 1861.28855508\n",
            "Iteration 13, loss = 1814.96411529\n",
            "Iteration 14, loss = 1762.46514763\n",
            "Iteration 15, loss = 1864.43497924\n",
            "Iteration 16, loss = 1888.64049700\n",
            "Iteration 17, loss = 1765.84570131\n",
            "Iteration 18, loss = 1678.77242077\n",
            "Iteration 19, loss = 1687.45587991\n",
            "Iteration 20, loss = 1615.72902970\n",
            "Iteration 21, loss = 1616.68160783\n",
            "Iteration 22, loss = 1589.75766021\n",
            "Iteration 23, loss = 1573.83813180\n",
            "Iteration 24, loss = 1562.39566376\n",
            "Iteration 25, loss = 1573.42905222\n",
            "Iteration 26, loss = 1546.83735197\n",
            "Iteration 27, loss = 1533.66486457\n",
            "Iteration 28, loss = 1530.32008619\n",
            "Iteration 29, loss = 1512.73213008\n",
            "Iteration 30, loss = 1499.48916210\n",
            "Iteration 31, loss = 1511.09126920\n",
            "Iteration 32, loss = 1497.94792225\n",
            "Iteration 33, loss = 1479.57787346\n",
            "Iteration 34, loss = 1474.71116211\n",
            "Iteration 35, loss = 1485.38949541\n",
            "Iteration 36, loss = 1496.10044545\n",
            "Iteration 37, loss = 1479.76796910\n",
            "Iteration 38, loss = 1471.51548619\n",
            "Iteration 39, loss = 1453.73085024\n",
            "Iteration 40, loss = 1521.47800844\n",
            "Iteration 41, loss = 1552.42860367\n",
            "Iteration 42, loss = 1457.30569334\n",
            "Iteration 43, loss = 1455.68364919\n",
            "Iteration 44, loss = 1491.20366783\n",
            "Iteration 45, loss = 1475.56585778\n",
            "Iteration 46, loss = 1448.69453563\n",
            "Iteration 47, loss = 1450.38526596\n",
            "Iteration 48, loss = 1461.59461993\n",
            "Iteration 49, loss = 1463.66017902\n",
            "Iteration 50, loss = 1480.47698909\n",
            "Iteration 51, loss = 1464.52434179\n",
            "Iteration 52, loss = 1462.26041040\n",
            "Iteration 53, loss = 1483.35092449\n",
            "Iteration 54, loss = 1451.10259648\n",
            "Iteration 55, loss = 1541.15656880\n",
            "Iteration 56, loss = 1466.59866678\n",
            "Iteration 57, loss = 1557.44620917\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "MSE for model 3: 2815.745866089745\n",
            "R2 score for model 3: 0.46854186143722487\n",
            "\n",
            "The best model based off of R2 score is: model 3\n",
            "The MSE for model 3 is : 2815.745866089745\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "diabetes = load_diabetes()\n",
        "x, y = diabetes.data, diabetes.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "mse_arr = []\n",
        "r2_score_arr = []\n",
        "\n",
        "model1 = MLPRegressor(\n",
        "  hidden_layer_sizes = (1000, 500, 300),\n",
        "  activation = 'relu',\n",
        "  solver = 'adam',\n",
        "  max_iter = 20,\n",
        "  batch_size = 16,\n",
        "  alpha = 0.0001,\n",
        "  random_state = 42,\n",
        "  verbose = True,\n",
        "  early_stopping = False)\n",
        "model1.fit(x_train, y_train)\n",
        "\n",
        "pred1 = model1.predict(x_test)\n",
        "mse1 = mean_squared_error(y_test, pred1)\n",
        "r2_1 = r2_score(y_test, pred1)\n",
        "print(f'MSE for model 1: {mse1}')\n",
        "print(f'R2 score for model 1: {r2_1}\\n')\n",
        "mse_arr.append(mse1)\n",
        "r2_score_arr.append(r2_1)\n",
        "\n",
        "model2 = MLPRegressor(\n",
        "  hidden_layer_sizes = (8, 64, 64, 64),\n",
        "  activation = 'relu',\n",
        "  solver = 'adam',\n",
        "  max_iter = 20,\n",
        "  batch_size = 8,\n",
        "  alpha = 0.0001,\n",
        "  random_state = 42,\n",
        "  verbose = True,\n",
        "  early_stopping = False)\n",
        "model2.fit(x_train, y_train)\n",
        "\n",
        "pred2 = model2.predict(x_test)\n",
        "mse2 = mean_squared_error(y_test, pred2)\n",
        "r2_2 = r2_score(y_test, pred2)\n",
        "print(f'MSE for model 2: {mse2}')\n",
        "print(f'R2 score for model 2: {r2_2}\\n')\n",
        "mse_arr.append(mse2)\n",
        "r2_score_arr.append(r2_2)\n",
        "\n",
        "model3 = MLPRegressor(\n",
        "  hidden_layer_sizes = (500, 100, 100, 100),\n",
        "  activation = 'relu',\n",
        "  solver = 'adam',\n",
        "  max_iter = 100,\n",
        "  batch_size =32,\n",
        "  alpha = 0.0001,\n",
        "  random_state = 42,\n",
        "  verbose = True,\n",
        "  early_stopping = False)\n",
        "model3.fit(x_train, y_train)\n",
        "\n",
        "pred3 = model3.predict(x_test)\n",
        "mse3 = mean_squared_error(y_test, pred3)\n",
        "r2_3 = r2_score(y_test, pred3)\n",
        "print(f'MSE for model 3: {mse3}')\n",
        "print(f'R2 score for model 3: {r2_3}\\n')\n",
        "mse_arr.append(mse3)\n",
        "r2_score_arr.append(r2_3)\n",
        "\n",
        "best_index = r2_score_arr.index(max(r2_score_arr))\n",
        "print(f'The best model based off of R2 score is: model {best_index + 1}')\n",
        "print(f'The MSE for model {best_index + 1} is : {mse_arr[best_index]}')"
      ]
    }
  ]
}